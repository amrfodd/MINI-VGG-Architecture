{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as k \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD \n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import argparse\n",
    "ap = argparse.ArgumentParser()\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((train_images, train_labels),(test_images, test_labels)) = cifar10.load_data()\n",
    "labelNames = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((train_images, test_images))\n",
    "y = np.concatenate((train_labels, test_labels))\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "train_images = train_images.reshape((54000, 32 , 32, 3))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((6000, 32, 32, 3))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# One Hot Encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVGG:\n",
    "    def build(width, height, depth, classes):\n",
    "        \n",
    "        model = Sequential()\n",
    "        inputshape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        if k.image_data_format() == \"channels_first\":\n",
    "            inputshape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "        # First Block\n",
    "        model.add(Conv2D(32, (3,3), padding = 'SAME', input_shape = inputshape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis =chanDim))\n",
    "        model.add(Conv2D(32, (3,3), padding = 'SAME'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis =chanDim))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2))) # as we dont add stridr keras put it to be equal max pooling \n",
    "        model.add(Dropout(0.25)) # to reduce overfitting\n",
    "        \n",
    "        # Second Block\n",
    "        model.add(Conv2D(64, (3,3), padding = 'SAME'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis =chanDim))\n",
    "        model.add(Conv2D(64, (3,3), padding = 'SAME'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(axis =chanDim))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5)) # between Layers\n",
    "        \n",
    "        # Classifier\n",
    "        \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling Model\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 780s 14ms/step - loss: 1.6063 - accuracy: 0.4324 - val_loss: 1.1944 - val_accuracy: 0.5743\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 747s 14ms/step - loss: 1.1924 - accuracy: 0.5764 - val_loss: 1.2486 - val_accuracy: 0.5800\n",
      "Epoch 3/5\n",
      "38016/54000 [====================>.........] - ETA: 3:50 - loss: 1.0133 - accuracy: 0.6440"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Compiling Model\")\n",
    "\n",
    "opt = SGD(lr= 0.01, decay = 0.01/ 40, momentum = 0.9, nesterov =True)\n",
    "# alpha = 0.01, Beta = 0.9 , decay rate of learning rate is (0.01/40)\n",
    "# nesetrov = true mean that we wold lik to apply nesetrov acclerated Gradient\n",
    "\n",
    "model = MiniVGG.build(width = 32, height = 32, depth = 3, classes =10) # instantiate Model \n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, validation_data = (test_images, test_labels), epochs=40, batch_size=64\n",
    "         verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating network\")\n",
    "predictions = model.predict(test_images, batch_size = 64)\n",
    "print(classification_report(test_labels.argmax(axis = 1),\n",
    "                           predictions.argmax(axis = 1), target_names = labelNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,40), H.history[\"loss\"], label = [\"train_loss\"])\n",
    "plt.plot(np.arange(0,40), H.history[\"val_loss\"], label = [\"val_loss\"])\n",
    "plt.plot(np.arange(0,40), H.history[\"acc\"], label = [\"train_acc\"])\n",
    "plt.plot(np.arange(0,40), H.history[\"val_acc\"], label = [\"val_acc\"])\n",
    "\n",
    "plt.title(\"Training loss and Accuracy on CIFAR-10\")\n",
    "plt.xlabel(\"EPOCH #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
